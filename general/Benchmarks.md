The only true valid list of benchmarks.

**General**
SimpleBench: [https://simple-bench.com/index.html](https://t.co/51rkwsB7pZ) 
SOLO-Bench: [https://github.com/jd-3d/SOLOBench](https://t.co/Zymtspj83V) 
AidanBench: [https://aidanbench.com](https://t.co/5lpH3CGhl0) 
SEAL by Scale: [https://scale.com/leaderboard](https://t.co/mAFyIfod7V) (particularly the MultiChallenge leaderboard) 
LMArena: [https://beta.lmarena.ai/leaderboard](https://t.co/CIOyTQ9ufe) (with Style Control) 
LiveBench: [https://livebench.ai](https://t.co/1fsq2IOsy1) 
ARC-AGI: [https://arcprize.org/leaderboard](https://t.co/bKh8xsI9WX) 
Thematic Generalization by LechMazur: [https://github.com/lechmazur/generalization…](https://t.co/W9FIyRedE6)
Confabulation Leaderboard for RAG [https://github.com/lechmazur/confabulations…](https://t.co/SrtUI7KYEZ)
Elimination Game [https://github.com/lechmazur/elimination_game…](https://t.co/vPDH3Aj5OO)
EQBench: [https://eqbench.com](https://t.co/g7zmT8Ilkq) (especially the Longform writing leaderboard) 
MC-Bench: [https://mcbench.ai/leaderboard](https://t.co/JpXYWvjk3Z) (ordered by winrate, not by Elo) 
TrackingAI - IQ Bench: [https://trackingai.org/home](https://t.co/rWoTwz1eu9) 
Dubesor LLM: [https://dubesor.de/benchtable.html](https://t.co/FyF32AKDa4) 
Balrog-AI: [https://balrogai.com](https://t.co/ZLwDpixw2E) 
Misguided Attention: [https://github.com/cpldcpu/MisguidedAttention…](https://t.co/2VMdPg5J4m) 
Snake-Bench: [https://snakebench.com](https://t.co/dEcvZYsVqz) 
SmolAgents LLM: [https://huggingface.co/spaces/smolagents/smolagents-leaderboard…](https://t.co/iBock5Q4V4) (just because of GAIA and SimpleQA) 
OpenCompass: [https://rank.opencompass.org.cn/home](https://t.co/GQbKwZDq8k)

**Long Context**
Context-Arena (MRCR and Graphwalks): [https://contextarena.ai](https://t.co/bXn2wwMK6L) 
Fiction-Live Bench: [https://fiction.live/stories/Fiction-liveBench-Mar-25-2025/oQdzQvKHw8JyXbN87…](https://t.co/NSA1d7LEGe) 
LoCoDiff https://abanteai.github.io/LoCoDiff-bench/index.html

**Coding**
Aider-Polyglot-Coding: [https://aider.chat/docs/leaderboards/…](https://t.co/aRGODg2PUA) 
BigCodeBench: [https://bigcode-bench.github.io](https://t.co/HxNMp3GLk9) 
WebDev-Arena: [https://web.lmarena.ai/leaderboard](https://t.co/sQB8tBLekG) 
WeirdML: [https://htihle.github.io/weirdml.html](https://t.co/38CA9RBml4) 
Symflower Coding: [https://symflower.com/en/company/blog/2025/dev-quality-eval-v1.0-anthropic-s-claude-3.7-sonnet-is-the-king-with-help-and-deepseek-r1-disappoints/…](https://t.co/WxYMXjcHpZ) 
SciCodeBench: https://scicode-bench.github.io/leaderboard/

**Agentic Code - AI Takeoff**
SWE-Lancer: [https://openai.com/index/swe-lancer/…](https://t.co/amsmTZYK7n) 
MLE-Bench: [https://github.com/openai/mle-bench…](https://t.co/2DkbRKdVA5) 
SWE-Bench: [https://swebench.com](https://t.co/TFJyzWqURA)

**Math**
PHYBench: [https://phybench-official.github.io/phybench-demo/](https://t.co/gyp0bGXxzt) 
MathArena: [https://matharena.ai](https://t.co/QVzZSeW9t9) 
FrontierMath: https://epoch.ai/frontiermath#version-history

**Agents**
Galileo Agent: [https://huggingface.co/spaces/galileo-ai/agent-leaderboard…](https://t.co/Igs3TW3s1I) 
XLANG Agent: [https://arena.xlang.ai/leaderboard](https://t.co/NZwxnbGMry)
GAIA2 https://huggingface.co/spaces/meta-agents-research-environments/leaderboard

**New model vibechecks**
GPQA-Diamond: [https://github.com/idavidrein/gpqa](https://t.co/t2HV6IiyaC) 
SimpleQA: [https://openai.com/index/introducing-simpleqa/…](https://t.co/lhpHqQcxJf) 
Tau-bench: [https://github.com/sierra-research/tau-bench…](https://t.co/TZT7fQc6cc) 
SciCode: [https://github.com/scicode-bench/SciCode…](https://t.co/J8HmPK9kiU) 
MMMU: [https://mmmu-benchmark.github.io/#leaderboard](https://t.co/rMHpsZQvRJ) 
Humanities Last Exam (HLE): [https://github.com/centerforaisafety/hle…](https://t.co/OHSoyPZ9nY)